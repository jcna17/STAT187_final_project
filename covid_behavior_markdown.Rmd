---
title: "Covid Behavior"
author: "Jake Campbell, Jin Lee, and Julie Grossman"
date: "4/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(usmap)
library(socviz)
library(grid)
library(C50)
library(gmodels)


theme_map <- function(base_size=9, base_family="") {
    require(grid)
    theme_bw(base_size=base_size, base_family=base_family) %+replace%
        theme(axis.line=element_blank(),
              axis.text=element_blank(),
              axis.ticks=element_blank(),
              axis.title=element_blank(),
              panel.background=element_blank(),
              panel.border=element_blank(),
              panel.grid=element_blank(),
              panel.spacing=unit(0, "lines"),
              plot.background=element_blank(),
              legend.justification = c(0,0),
              legend.position = c(0,0)
              )
}



raw_data <- read_csv("covid_behavior.csv")
```

## I. Introduction
This data, which examines people’s behaviors in response to the COVID-19 pandemic, comes from Imperial College London. The data also includes information about COVID-19 test results. Data collection started in March 2020 and is ongoing,, but the subset of the data being used for this project was collected between March 2020 and July 2020. The dataset description does not detail the sampling method, but it states that responses are nationally representative of the general public and that, “people with severe symptoms, people who have been hospitalized, and some other hard to reach group will be under-represented in the sample.” No other sampling bias is suspected. 

This data was collected through interviews and represents an observational study, as there is no direct intervention by the researchers. No bias is suspected in the questions as they were created by a well-respected institution and measure primarily objective factors, such as frequencies as counts. The measurements may be biased towards behaviors that are seen as socially acceptable as people may not feel comfortable admitting to a researcher that they don’t do things like wear a mask or avoid large gatherings.

This data is very relevant as it is about a pandemic that is ongoing. It has been shown that individual behavior has a significant impact on the spread of COVID-19, so examining COVID-related behavior across the United States could potentially be used to identify areas that are likely to have outbreaks. It’s also interesting to observe how COVID-related behavior varies across the United States.

The data was cleaned by first removing the second row of column headers. Columns that were not of interest were removed, and then the remaining columns were renamed to make them easier to work with. All of the data was read in as character data, so columns that contained factor or numeric data were transformed into their respective data type. The data cleaning code can be seen below.


```{r subset_rename}
#select columns of interest
data <- raw_data %>%
  select("endtime" : "i13_health", "gender" : "employment_status")

#display names before renaming
head(names(data), 10)

#rename columns
new_names <- c("endtime", 
               "state", "qweek", 
               "hh_contact", "non_hh_contact",
               "n_leave_home", "tested", 
               "hh_tested", "cough", 
               "fever", "lost_smell",
               "lost_taste", "short_of_breath", 
               "no_symp", "contact_symp_person",
               "isolate_after_symp", "doctor_after_symp", 
               "travel_before_symp", "isolate_if_symp", 
               "isolation_ease", "isolation_willingness", 
               "mask", "hand_washing", 
               "sanitizer", "cover_mouth", 
               "avoid_symp_person", "avoid_going_out", 
               "avoid_healthcare", "avoid_pub_transport",
               "avoid_work_not_home", "avoid_school_not_home", 
               "avoid_guests", "avoid_s_gath", 
               "avoid_m_gath", "avoid_l_gath", 
               "avoid_crowds", "avoid_shopping", 
               "stop_share_bedroom", "stop_share_meals",
               "surface_cleaning", "avoid_touching_public_objects", 
               "n_wash_sanitize", "gender", 
               "age", "hh_size",
               "hh_children", "emp_status"
               )

names(data) <- new_names

#display names after renaming
head(names(data), 10)

```
```{r recode, warning = FALSE}
#display data summary before recoding
#note how all columns are character data
head(summary(data[13:20]))

#commonly used factor levels
yn_levels <- c("No", "Yes")
freq_levels <- c("Not at all", "Rarely", "Sometimes", "Frequently", "Always")

data_recode <- data %>%
  #convert from character to numeric
  mutate(hh_contact = as.numeric(hh_contact),
         non_hh_contact = as.numeric(non_hh_contact),
         n_leave_home = as.numeric(n_leave_home),
         age = as.numeric(age),
         hh_size = as.numeric(hh_size),
         hh_children = as.numeric(hh_children),
         n_wash_sanitize = as.numeric(n_wash_sanitize)
         ) %>%
  #convert from yes/no character to factor
  mutate(cough = factor(cough, levels = yn_levels),
         fever = factor(fever, levels = yn_levels),
         lost_smell = factor(lost_smell, levels = yn_levels),
         lost_taste = factor(lost_taste, levels = yn_levels),
         short_of_breath = factor(short_of_breath, levels = yn_levels),
         no_symp = factor(no_symp, levels = yn_levels),
         doctor_after_symp = factor(doctor_after_symp, levels = yn_levels),
         ) %>%
  #convert from frequency character to factor
  mutate(mask = factor(mask, levels = freq_levels),
         hand_washing = factor(hand_washing, levels = freq_levels),
         sanitizer = factor(sanitizer, levels = freq_levels),
         cover_mouth = factor(cover_mouth, levels = freq_levels),
         avoid_symp_person = factor(avoid_symp_person, levels = freq_levels),
         avoid_going_out = factor(avoid_going_out, levels = freq_levels),
         avoid_healthcare = factor(avoid_healthcare, levels = freq_levels),
         avoid_pub_transport = factor(avoid_pub_transport, levels = freq_levels),
         avoid_work_not_home = factor(avoid_work_not_home, levels = freq_levels),
         avoid_school_not_home = factor(avoid_school_not_home, levels = freq_levels),
         avoid_guests = factor(avoid_guests, levels = freq_levels),
         avoid_s_gath = factor(avoid_s_gath, levels = freq_levels),
         avoid_m_gath = factor(avoid_m_gath, levels = freq_levels),
         avoid_l_gath = factor(avoid_l_gath, levels = freq_levels),
         avoid_crowds = factor(avoid_crowds, levels = freq_levels),
         avoid_shopping = factor(avoid_shopping, levels = freq_levels),
         stop_share_bedroom = factor(stop_share_bedroom, levels = freq_levels),
         stop_share_meals = factor(stop_share_meals, levels = freq_levels),
         surface_cleaning = factor(surface_cleaning, levels = freq_levels),
         avoid_touching_public_objects = factor(avoid_touching_public_objects, levels = freq_levels),
         isolate_after_symp = factor(isolate_after_symp, levels = freq_levels)
         ) %>%
  #convert other characters to factor
  mutate(tested = factor(tested, 
                         levels = c("No, I have not", "Yes, and I tested positive",
                                            "Yes, and I have not received my results from the test yet",                                                 "Yes, and I tested negative"),
                         labels = c("N", "Y+", "Y~", "Y-")),
         hh_tested = factor(hh_tested, 
                            levels = c("No, they have not", "Yes, and they tested positive",
                                                  "Yes, and they have not received their results from the test yet", "Yes, and they tested negative"), 
                            labels = c("N", "Y+", "Y~", "Y-")),
         gender = factor(gender, levels = c("Male", "Female")),
         contact_symp_person = factor(contact_symp_person,
                                      levels = c("Not sure", "No", "Yes")),
         travel_before_symp = factor(travel_before_symp,levels = c("Not sure", "No", "Yes")),
         isolate_if_symp = factor(isolate_if_symp, levels = c("Not sure", "No", "Yes")),
         isolation_ease = factor(isolation_ease, 
                                 levels = c("Not sure", "Very difficult", "Somewhat difficult",
                                            "Neither easy nor difficult", "Somewhat easy",
                                            "Very easy")),
         isolation_willingness = factor(isolation_willingness,
                                        levels = c("Not sure", "Very unwilling",
                                                   "Somewhat unwilling",
                                                   "Neither willing nor unwilling",
                                                   "Somewhat willing", "Very willing")),
         emp_status = factor(emp_status,
                                    levels = c("Other", "Retired", "Not working", "Unemployed",
                                               "Full time student", "Part time employment",
                                               "Full time employment")),
         qweek = factor(qweek,
                        levels = c("week 1", "week 2", "week 3", "week 4", "week 5", "week 6", "week 7", "week 8", "week 9", "week 10", "week 11", "week 12", "week 13"))
                                 
         
         )


#display data summary after recoding
head(summary(data_recode[13:20]))

```




## II. Data Visualizations

A bar graph of positive and negative test results by mask usage demonstrates that the more often one wears a mask, the more likely they are to test negative for COVID-19. 
```{r masks, message = FALSE, warning = FALSE}
# data with applied filters  
test_data <- data_recode %>% filter(tested == 'Y+' | tested == 'Y-')

# # Graph 1: positive tests v. mask wearing 

# Tests Results v. Mask Usage
mask1 <- ggplot(data = test_data, mapping = aes(x = mask, fill = tested)) +
  geom_bar(position = 'dodge') +
  labs(title = "Test Results by Mask Wearing Frequency", 
       x = "Frequency of Mask Wearing", 
       y = "Number of Results",
       fill = "Test Result") +
  theme(plot.title = element_text(face = 'bold', size = 15, hjust = .5))+
  scale_fill_discrete(labels = (c("Positive", "Negative")))

mask1
```

Density plots of hand washing and sanitizing habits compared to test results demonstrates that the more often one washes their hands, the more likely they are to test negative for COVID-19. 
```{r sanitizing, message = FALSE, warning = FALSE}
# # Graph 2: positive tests v. number of times sanitizing per day 

# Data modification
sanitizing_data <- test_data %>% 
  filter(n_wash_sanitize < 75) %>% 
  group_by(n_wash_sanitize, tested) %>% 
  summarise(sampsize = n()) %>% 
  ungroup()



# Test Results v. Number of Times of Hand Washing per Day
sanitizing1 <- ggplot(data = sanitizing_data, 
                      mapping = aes(x = n_wash_sanitize, fill = tested)) +
  geom_density(alpha = .5, color = 'black') +
  labs(title = "Handwashing Densities by Test Result", 
       x = "Frequency of Hand Washing (Daily)", 
       y = "Density") +
  #theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        #plot.title = element_text(face = 'bold', size = 15, hjust = .5)) +
  guides(fill = guide_legend(title = "Test Result"))+
  scale_fill_discrete(labels = (c("Positive", "Negative")))
sanitizing1


```

A bar graph of test results per week over time (13 weeks) shows the fluctuation of positive COVID-19 tests over the time period. 
```{r time, message = FALSE, warning = FALSE}
# # Graph 3: positive tests v. time

# Data modification
time_data <- test_data %>% 
  filter(tested == 'Y+') %>% 
  group_by(tested, qweek) %>% 
  summarise(sampsize = n()) %>% 
  ungroup()


# Positive Cases by Time

time1 <- ggplot(data = time_data, mapping = (aes(x = qweek, y = sampsize))) +
  geom_col(fill = "#f8766d") +
  guides(fill = FALSE) +
  labs(title = "Positive Tests by Week", x = "Week", y = "Count") +
  scale_x_discrete(labels = c(1:13)) +
  theme(plot.title = element_text(face = 'bold', size = 15, hjust = .5))
time1

```



```{r sanitize data, warning = FALSE}
# merge data_recode with map_data
us_states <- map_data("state")
data_recode$region <- tolower(data_recode$state)


us_states_recode <- us_states %>%
   left_join(data_recode, by = 'region')

# Filter it under 30 because most of the value of washing hands is under 30
# if the range is too huge, the mapping will not be able to emphasize what the data  actually means.
us_sanitize<-us_states_recode %>% filter(n_wash_sanitize <30)

tibble(us_sanitize)

```

```{r sanitize map}
# draw a map about Frequecy of handwashing by state
ggplot(data = us_sanitize,
   mapping = aes(x = long, y = lat,  group = group, fill = n_wash_sanitize))  +
  geom_polygon(color = "lightgrey") +
  scale_fill_continuous(low = 'red', high = 'cyan') +
 coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  labs(title = "Average Number of Handwashings per Day") +
  labs(fill = "Number of Handwashings") +
  theme_map()+
   theme(plot.title = element_text(face = 'bold', size = 15, hjust = .5),
        legend.position = "right")

```


```{r mask data, warning = FALSE}
# change the value of mask to numeric
tibble(as.numeric(data_recode$mask))

# calculate state mask wearing averages
stats1 <- data_recode %>%
  group_by(state) %>%
  summarise( mmask = mean(as.numeric(mask), na.rm = TRUE))

#merge stats1 data with us_states
stats1$region <- tolower(stats1$state)

us_mask <- us_states %>%
   left_join(stats1, by = 'region')

```
```{r mask map}
# draw a map of mean mask wearing by state
ggplot(data = us_mask,
   mapping = aes(x = long, y = lat,  group = group, fill = mmask))  +
  geom_polygon(color = "lightgrey") +
  scale_fill_continuous(low = 'red', high = 'cyan',
                        breaks = c(2.4, 4),
                        labels = c("Rarely", "Frequently"))+
 coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  labs(title = "Mask Wearing Frequency") +
  labs(fill = "Mask Wearing Frequency") +
  theme_map()+
  theme(plot.title = element_text(face = 'bold', size = 15, hjust = .5),
        legend.position = "right")
 
```




## III. Machine Learning Methods
```{r mlprep}
test_results <- data_recode %>%
  #select only observations that have a positive or negative test result
  filter(tested %in% c("Y-", "Y+")) %>%
  #select columns to be used in training of model
  select(-endtime, -state, -qweek, -hh_tested, -cough, -fever, -short_of_breath, -lost_smell, -lost_taste,
         -short_of_breath, -no_symp, -contact_symp_person, -isolate_after_symp, -doctor_after_symp,
         -travel_before_symp, -hh_size, -hh_children, -avoid_work_not_home, -avoid_school_not_home, -age,
         -gender, -emp_status) %>%
  #refactors tested column so that only levels are positive and negative
  mutate(tested = droplevels(tested))

#check to ensure that there are no NA observations
sum(is.na(test_results))
         
#generate random numbers for creating train and test set
test_sample <- sample(1:955, 800)

#create training data
test_results_train <- test_results[test_sample,]
test_results_train <- test_results_train %>%
  select(-region)
test_results_train_labels <- as.data.frame(test_results[test_sample,])


#create testing data
test_results_test <- test_results[-test_sample,]
test_results_test <- test_results_test %>%
  select(-region)
test_results_test_labels <- as.data.frame(test_results[-test_sample,])

```
```{r mltrain}
#create the model
test_results_model <- C5.0(tested ~ ., data = test_results_train)

#show information about the model
test_results_model
summary(test_results_model)
```
```{r mltest}
#assess the accuracy of the model
test_results_predict <- predict(test_results_model, test_results_test[-4])

CrossTable(test_results_test$tested, test_results_predict,
            prop.chisq = FALSE, prop.c =FALSE,
            prop.r = FALSE, 
            dnn = c('actual data', 'predicted data'))


```
```{r predictfull}
data_recode_predict <- data_recode %>%
  #select columns used by model for full dataset
  select(-endtime, -qweek, -hh_tested, -cough, -fever, -short_of_breath, -lost_smell, -lost_taste,
         -short_of_breath, -no_symp, -contact_symp_person, -isolate_after_symp, -doctor_after_symp,
         -travel_before_symp, -hh_size, -hh_children, -avoid_work_not_home, -avoid_school_not_home, -age,
         -gender, -emp_status, -tested)

data_recode_predict2 <- data_recode %>%
  select(state, hh_contact, non_hh_contact, n_leave_home, isolate_if_symp:avoid_pub_transport,
         avoid_guests:n_wash_sanitize)

data_recode_predict_no_state <- data_recode_predict2 %>%
  select(-state)

#add prediction column
##CHECK THIS LINE
data_recode_predict2$pred <- predict(test_results_model, data_recode_predict_no_state)

#check for NAs
sum(is.na(test_results))



```

```{r predictmapdata, message = FALSE}
predict_map_data <- data_recode_predict2 %>%
  #make a column of the predictions as integers so positive cases can be counted
  mutate(pred_int = ifelse(pred == "Y+", 1, 0)) %>%
  #group by state and determine percent of positive cases
  group_by(state) %>%
  summarize(
    count = n(),
    positive_cases = sum(pred_int),
    percent_cases = positive_cases / count * 100
  ) %>%
  mutate(region = tolower(state)) %>%
  ungroup()

us_states <- map_data("state")
predict_map_join <- us_states %>%
   left_join(predict_map_data, by = "region")
```


```{r predictmap}
ggplot(data = predict_map_join,
   mapping = aes(x = long, y = lat,  group = group, fill = percent_cases))  +
  geom_polygon(color = "lightgrey") +
  scale_fill_continuous(low = "gray", high = "red") +
 coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  labs(title = "Percent of Population Predicted to Test Positive") +
  labs(fill = "% Positive Cases") +
  theme_map()+
   theme(plot.title = element_text(face = 'bold', size = 15, hjust = .5),
        legend.position = "right")

```


## IV. Conclusions

## V. Limitations/Recommendations




